// inline fn ghash(reg u128 input, reg u128 h, reg u32 i) -> reg u128 {
// 	// H is the hash key
// 	// A is the additional authenticated data
// 	// C is the ciphertext

// 	reg u128 hash_value;
// 	// Initialize the hash value to zero
// 	hash_value = #set0_128();

// 	// Process the additional authenticated data (AAD)
// 	// for each block a_block in A:
// 	// 	hash_value = multiply_in_gf(hash_value, H)
// 	// 	hash_value = xor(hash_value, a_block)
// 	hash_value = #VPXOR(hash_value, a); // xor
// 	hash_value = #VPCLMULQDQ(hash_value, h, 128); // mult GF(2^128)

// 	// Process the ciphertext
// 	// for each block c_block in C:
// 	// 	hash_value = multiply_in_gf(hash_value, H)
// 	// 	hash_value = xor(hash_value, c_block)
// 	hash_value = #VPXOR(hash_value, c); // xor
// 	hash_value = #VPCLMULQDQ(hash_value, h, 128); // mult GF(2^128)

// 	return hash_value;
// }


u64[2] AND_MASK = {0x0f0f0f0f0f0f0f0f, 0x0f0f0f0f0f0f0f0f};
u64[2] LOWER_MASK = {0x0f070b030d050901, 0x0e060a020c040800};
u64[2] HIGHER_MASK = {0xf070b030d0509010, 0xe060a020c0408000};
u64[2] BSWAP_MASK = {0x000102030405060708,0x090a0b0c0d0e0f};

inline fn reflecting_bit_128(reg u64 ptr_x) {
	reg u128 temp1 temp2 mask;
	mask = #VPINSR_2u64(mask, AND_MASK[0], 0);
	mask = #VPINSR_2u64(mask, AND_MASK[1], 1);
	
	temp2 = (u128)[ptr_x];
	temp2 = #VPSRL_8u16(temp2, 4);

	temp1 = (u128)[ptr_x];
	temp1 = #VPAND_128(temp1, mask);

	temp2 = #VPAND_128(temp2, mask);

	reg u128 higher_mask;
	higher_mask = #VPINSR_2u64(higher_mask, HIGHER_MASK[0], 1);
	higher_mask = #VPINSR_2u64(higher_mask, HIGHER_MASK[1], 0);
	temp1 = #VPSHUFB(higher_mask, temp1);

	reg u128 lower_mask;
	lower_mask = #VPINSR_2u64(lower_mask, LOWER_MASK[0], 1);
	lower_mask = #VPINSR_2u64(lower_mask, LOWER_MASK[1], 0);
	temp2 = #VPSHUFB_128(lower_mask, temp2);
	
	temp1 = #VPXOR_128(temp1, temp2);

	global u128 swap_me;
    swap_me = (16u8)[ 0, 1 , 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15];
	
	temp1 = #VPSHUFB_128(temp1, swap_me);
	(u128)[ptr_x] = temp1;
}

inline fn ghash(reg u128 input, reg u128 h, reg u32 i) -> reg u128 {
	// VPCLMULQDQ https://www.felixcloutier.com/x86/pclmulqdq

	// https://www.intel.com/content/dam/develop/external/us/en/documents/clmul-wp-rev-2-02-2014-04-20.pdf
	// Karatsuba multiplication (Intel spec page 13 algo 2)
	// We want to multiply two 128-bit numbers: [A1:A0] and [B1:B0]
	// [C1:C0] = A1*B1
	// [D1:D0] = A0*B0
	// [E1:E0] = (A0⊕A1)*(B0⊕B1)
	reg u128 a; a = input;
	reg u128 b; b = h;
	
	reg u128 c; c = #set0_128(); c = #VPCLMULQDQ(a, b, 0x11);
	reg u128 d; d = #set0_128(); d = #VPCLMULQDQ(a, b, 0x00);

	reg u64 a0; a0 = 0; a0 = #VPEXTR_64(a, 0);
	reg u64 a1; a1 = 0; a1 = #VPEXTR_64(a, 1);
	reg u64 xor_a; xor_a = a0; xor_a ^= a1;
	reg u64 b0; b0 = 0; b0 = #VPEXTR_64(b, 0);
	reg u64 b1; b1 = 0; b1 = #VPEXTR_64(b, 1);
	reg u64 xor_b; xor_b = b0; xor_b ^= b1;
	reg u128 xor_a_128; xor_a_128 = (128u) xor_a;
	reg u128 xor_b_128; xor_b_128 = (128u) xor_b;
	reg u128 e; e = #set0_128(); e = #VPCLMULQDQ(xor_a_128, xor_b_128, 0x00);

	e = #VPXOR(e, d);
	e = #VPXOR(e, c);

	reg u128 temp temp3 temp4 temp5 temp6 temp7;
	temp = #set0_128();
	reg u64 temp2;
	temp2 = #VPEXTR_64(e, 0);
	temp2 = temp2;
	temp = #VPINSR_2u64(temp, temp2, 1);
	temp2 = 0;
	temp2 = #VPEXTR_64(e, 1);
	e = #set0_128();
	e = (128u) temp2;
	d = #VPXOR(d, temp);
	c = #VPXOR(c, e);

	temp3 = #set0_128();
	temp4 = #set0_128();
	temp3 = #VPSRL_4u32(c, 31);
	temp4 = #VPSRL_4u32(c, 30);
	temp5 = #VPSRL_4u32(c, 25);

	temp3 = #VPXOR(temp3, temp4);
	temp3 = #VPXOR(temp3, temp5);

	temp6 = #set0_128();
	temp6 = #VPSHUFD_128(temp3, 147);

	temp7 = #set0_128();
	reg u64 temp8;
	temp8 = 0xffffffff;
	temp7 = #VPINSR_2u64(temp7, temp8, 0);

	temp3 = #VPAND_128(temp7, temp6);

	temp6 = #VPANDN_128(temp7, temp6);

	d = #VPXOR(d, temp6);
	c = #VPXOR(c, temp3);

	temp7 = #set0_128();
	temp7 = #VPSLL_4u32(c, 1);
	d = #VPXOR(d, temp7);

	temp7 = #set0_128();
	temp7 = #VPSLL_4u32(c, 2);
	d = #VPXOR(d, temp7);

	temp7 = #set0_128();
	temp7 = #VPSLL_4u32(c, 7);
	d = #VPXOR(d, temp7);

	reg u128 res;
	res = #set0_128();
	res = d;
	res = #VPXOR(res, c);

	return res;
}

// DEBUG x0
// 00011111111101001010011110001010011100000110100010000100101100000100011100111110111111100111010101100000001110000111000111010000

// DEBUG x3
// 00000000100110110101011101000001100010000001111000000111100010010000001110100010100110110001101001001011010000111100101011110100

inline fn ghash_xor(reg u128 ghash_prev, reg u128 data, reg u128 h, reg u32 i) -> reg u128 {
	reg u128 hash_value;
	hash_value = ghash_prev;

	hash_value = #VPXOR(hash_value, data); // xor


	hash_value = ghash(hash_value, h, i);

	return hash_value;
}

// inline fn everything(reg u128 p, reg u128 k, reg u128 iv0, reg u128 iv1) -> reg u128 {
// 	reg u128 hash_value;
// 	hash_value = ghash_prev;

// 	hash_value = #VPXOR(hash_value, data); // xor


// 	hash_value = ghash(hash_value, h, i);

// 	return hash_value;
// }
